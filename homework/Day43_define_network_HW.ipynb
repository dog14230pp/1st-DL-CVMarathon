{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.4"},"colab":{"name":"Day43_define_network_HW.ipynb","provenance":[],"collapsed_sections":[]}},"cells":[{"cell_type":"markdown","metadata":{"id":"mPC5mHvNAG0n","colab_type":"text"},"source":["### 作業\n","請嘗試使用 keras 來定義一個直接預測 15 個人臉關鍵點坐標的檢測網路，以及適合這個網路的 loss function\n","\n","\n","Hint: 參考前面的電腦視覺深度學習基礎"]},{"cell_type":"markdown","metadata":{"id":"y8uoDLTXAG0q","colab_type":"text"},"source":["### 範例\n","接下來的程式碼會示範如何定義一個簡單的 CNN model"]},{"cell_type":"code","metadata":{"id":"_yU8PPcYAG0r","colab_type":"code","colab":{}},"source":["import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","%matplotlib inline"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"AJKnAt7PAG0w","colab_type":"code","outputId":"c9fa83d3-75c8-459f-dd3d-e1c82df66acb","executionInfo":{"status":"ok","timestamp":1582628450662,"user_tz":-480,"elapsed":26330,"user":{"displayName":"孫浩倫","photoUrl":"","userId":"12758391630570192782"}},"colab":{"base_uri":"https://localhost:8080/","height":255}},"source":["# 使用 colab 環境的同學請執行以下程式碼\n","%tensorflow_version 1.x # 確保 colob 中使用的 tensorflow 是 1.x 版本而不是 tensorflow 2\n","import tensorflow as tf\n","print(tf.__version__)\n","\n","import os\n","from google.colab import drive \n","drive.mount('/content/gdrive') # 將 google drive 掛載在 colob，\n","%cd gdrive/'My Drive'\n","os.system(\"mkdir cupoy_cv_part4\") # 可以自己改路徑\n","%cd cupoy_cv_part4 "],"execution_count":0,"outputs":[{"output_type":"stream","text":["`%tensorflow_version` only switches the major version: `1.x` or `2.x`.\n","You set: `1.x # 確保 colob 中使用的 tensorflow 是 1.x 版本而不是 tensorflow 2`. This will be interpreted as: `1.x`.\n","\n","\n","TensorFlow 1.x selected.\n","1.15.0\n","Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n","\n","Enter your authorization code:\n","··········\n","Mounted at /content/gdrive\n","/content/gdrive/My Drive\n","/content/gdrive/My Drive/cupoy_cv_part4\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"RK56WprbAG0z","colab_type":"code","colab":{}},"source":["# 讀取資料集以及做前處理的函數\n","def load_data(dirname):\n","    # 讀取 csv 文件\n","    data = pd.read_csv(dirname)\n","    # 過濾有缺失值的 row\n","    data = data.dropna()\n","\n","    # 將圖片像素值讀取為 numpy array 的形態\n","    data['Image'] = data['Image'].apply(lambda img: np.fromstring(img, sep=' ')).values \n","\n","    # 單獨把圖像 array 抽取出來\n","    imgs = np.vstack(data['Image'].values)/255\n","    # reshape 為 96 x 96\n","    imgs = imgs.reshape(data.shape[0], 96, 96)\n","    # 轉換為 float\n","    imgs = imgs.astype(np.float32)\n","    \n","    # 提取坐標的部分\n","    points = data[data.columns[:-1]].values\n","\n","    # 轉換為 float\n","    points = points.astype(np.float32)\n","\n","    # normalize 坐標值到 [-0.5, 0.5]\n","    points = points/96 - 0.5\n","    \n","    return imgs, points"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"RXnfdcHJAG03","colab_type":"code","outputId":"db68f0d7-3cb0-45e5-93a5-95376a3e45ed","executionInfo":{"status":"ok","timestamp":1582628465888,"user_tz":-480,"elapsed":13202,"user":{"displayName":"孫浩倫","photoUrl":"","userId":"12758391630570192782"}},"colab":{"base_uri":"https://localhost:8080/","height":50}},"source":["# 讀取資料\n","imgs_train, points_train = load_data(dirname = 'training.csv')\n","print(\"圖像資料:\", imgs_train.shape, \"\\n關鍵點資料:\", points_train.shape)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["圖像資料: (2140, 96, 96) \n","關鍵點資料: (2140, 30)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"6E4ZJPuIAG06","colab_type":"code","outputId":"e9b558d4-b083-4ab0-dd10-5ba7400d5b75","executionInfo":{"status":"ok","timestamp":1582628465889,"user_tz":-480,"elapsed":623,"user":{"displayName":"孫浩倫","photoUrl":"","userId":"12758391630570192782"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["from keras.models import Sequential\n","from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Using TensorFlow backend.\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"L3CiNNHZAG0-","colab_type":"code","colab":{}},"source":["# 定義人臉關鍵點檢測網路\n","model = Sequential()\n","\n","model.add(Conv2D(64, (3, 3), activation='relu', padding='same', input_shape = (96, 96, 1)))\n","model.add(Conv2D(64, (3, 3), activation='relu', padding='same'))\n","model.add(MaxPooling2D((2, 2), strides=(2, 2)))\n","\n","model.add(Conv2D(128, (3, 3), activation='relu', padding='same'))\n","model.add(Conv2D(128, (3, 3), activation='relu', padding='same'))\n","model.add(MaxPooling2D((2, 2), strides=(2, 2)))\n","\n","model.add(Conv2D(256, (3, 3), activation='relu', padding='same'))\n","model.add(Conv2D(256, (3, 3), activation='relu', padding='same'))\n","model.add(Conv2D(256, (3, 3), activation='relu', padding='same'))\n","model.add(MaxPooling2D((2, 2), strides=(2, 2)))\n","\n","model.add(Conv2D(512, (3, 3), activation='relu', padding='same'))\n","model.add(Conv2D(512, (3, 3), activation='relu', padding='same'))\n","model.add(Conv2D(512, (3, 3), activation='relu', padding='same'))\n","model.add(MaxPooling2D((2, 2), strides=(2, 2)))\n","\n","model.add(Conv2D(512, (3, 3), activation='relu', padding='same'))\n","model.add(Conv2D(512, (3, 3), activation='relu', padding='same'))\n","model.add(Conv2D(512, (3, 3), activation='relu', padding='same'))\n","model.add(MaxPooling2D((2, 2), strides=(2, 2)))\n","\n","model.add(Flatten())\n","model.add(Dense(256))\n","model.add(Dense(30))\n","\n","# 配置 loss funtion 和 optimizer\n","model.compile(loss='mean_squared_error', optimizer='adam')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"iDEESR3nAG1D","colab_type":"code","outputId":"43481a31-80c3-454a-fd31-f2b597f07938","executionInfo":{"status":"ok","timestamp":1582628960117,"user_tz":-480,"elapsed":691,"user":{"displayName":"孫浩倫","photoUrl":"","userId":"12758391630570192782"}},"colab":{"base_uri":"https://localhost:8080/","height":857}},"source":["model.summary()"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Model: \"sequential_3\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","conv2d_27 (Conv2D)           (None, 96, 96, 64)        640       \n","_________________________________________________________________\n","conv2d_28 (Conv2D)           (None, 96, 96, 64)        36928     \n","_________________________________________________________________\n","max_pooling2d_11 (MaxPooling (None, 48, 48, 64)        0         \n","_________________________________________________________________\n","conv2d_29 (Conv2D)           (None, 48, 48, 128)       73856     \n","_________________________________________________________________\n","conv2d_30 (Conv2D)           (None, 48, 48, 128)       147584    \n","_________________________________________________________________\n","max_pooling2d_12 (MaxPooling (None, 24, 24, 128)       0         \n","_________________________________________________________________\n","conv2d_31 (Conv2D)           (None, 24, 24, 256)       295168    \n","_________________________________________________________________\n","conv2d_32 (Conv2D)           (None, 24, 24, 256)       590080    \n","_________________________________________________________________\n","conv2d_33 (Conv2D)           (None, 24, 24, 256)       590080    \n","_________________________________________________________________\n","max_pooling2d_13 (MaxPooling (None, 12, 12, 256)       0         \n","_________________________________________________________________\n","conv2d_34 (Conv2D)           (None, 12, 12, 512)       1180160   \n","_________________________________________________________________\n","conv2d_35 (Conv2D)           (None, 12, 12, 512)       2359808   \n","_________________________________________________________________\n","conv2d_36 (Conv2D)           (None, 12, 12, 512)       2359808   \n","_________________________________________________________________\n","max_pooling2d_14 (MaxPooling (None, 6, 6, 512)         0         \n","_________________________________________________________________\n","conv2d_37 (Conv2D)           (None, 6, 6, 512)         2359808   \n","_________________________________________________________________\n","conv2d_38 (Conv2D)           (None, 6, 6, 512)         2359808   \n","_________________________________________________________________\n","conv2d_39 (Conv2D)           (None, 6, 6, 512)         2359808   \n","_________________________________________________________________\n","max_pooling2d_15 (MaxPooling (None, 3, 3, 512)         0         \n","_________________________________________________________________\n","flatten_2 (Flatten)          (None, 4608)              0         \n","_________________________________________________________________\n","dense_3 (Dense)              (None, 256)               1179904   \n","_________________________________________________________________\n","dense_4 (Dense)              (None, 30)                7710      \n","=================================================================\n","Total params: 15,901,150\n","Trainable params: 15,901,150\n","Non-trainable params: 0\n","_________________________________________________________________\n"],"name":"stdout"}]}]}